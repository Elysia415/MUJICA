from __future__ import annotations

import json
import os
import sys
from pathlib import Path

import streamlit as st

# ç¡®ä¿é¡¹ç›®æ ¹ç›®å½•åœ¨ sys.pathï¼Œæ–¹ä¾¿ `import src.*`
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

from src.utils.env import load_env
from src.utils.llm import get_llm_client
from src.data_engine.storage import KnowledgeBase
from src.data_engine.loader import DataLoader
from src.data_engine.fetcher import ConferenceDataFetcher
from src.data_engine.ingestor import OpenReviewIngestor
from src.planner.agent import PlannerAgent
from src.researcher.agent import ResearcherAgent
from src.writer.agent import WriterAgent
from src.verifier.agent import VerifierAgent


def _ensure_streamlit_context() -> bool:
    """
    åœ¨é `streamlit run` åœºæ™¯ä¸‹é¿å… session_state æŠ¥é”™ï¼ˆä¾‹å¦‚è¯¯ç”¨ `python ui/app.py`ï¼‰ã€‚
    """
    try:
        from streamlit.runtime.scriptrunner.script_run_context import get_script_run_ctx

        return get_script_run_ctx() is not None
    except Exception:
        # Streamlit å†…éƒ¨ API å˜åŒ–æ—¶ï¼Œå°½é‡ä¿æŒå¯è¿è¡Œï¼ˆæœ€åæƒ…å†µä¸åŸæ¥ä¸€è‡´ï¼‰
        return True


def _local_css(css_path: Path) -> None:
    if css_path.exists():
        st.markdown(f"<style>{css_path.read_text(encoding='utf-8')}</style>", unsafe_allow_html=True)


def _render_data_dashboard() -> None:
    st.header("ğŸ’¾ Knowledge Base Management")

    tab1, tab2 = st.tabs(["Ingest Local Data", "OpenReview Crawler"])

    with tab1:
        st.subheader("Load Local Samples")
        if st.button("Load Test Dataset (Samples)"):
            with st.spinner("Ingesting sample data..."):
                kb = KnowledgeBase()
                kb.initialize_db()
                loader = DataLoader("data/raw/test_samples.json")

                if not os.path.exists("data/raw/test_samples.json"):
                    sample_papers = [
                        {"id": "p1", "title": "Self-Rewarding Language Models", "abstract": "We propose...", "rating": 9.0},
                        {"id": "p2", "title": "Direct Preference Optimization", "abstract": "DPO is stable...", "rating": 9.5},
                    ]
                    loader.save_local_data(sample_papers)

                data = loader.load_local_data()
                kb.ingest_data(data)
                st.success(f"Ingested {len(data)} papers into LanceDB!")

    with tab2:
        st.subheader("Crawl OpenReview (Live)")
        venue_id = st.text_input("Venue ID", "NeurIPS.cc/2024/Conference")
        limit = st.slider("Max Papers", 10, 100, 20)
        download_pdfs = st.checkbox("Download PDFs", value=True)
        parse_pdfs = st.checkbox("Parse PDFs to Full Text", value=True, disabled=not download_pdfs)
        max_pages = st.slider("Max PDF pages to parse", 1, 50, 12, disabled=not parse_pdfs)

        if st.button("Fetch & Ingest"):
            kb = KnowledgeBase()
            kb.initialize_db()
            ingestor = OpenReviewIngestor(kb, fetcher=ConferenceDataFetcher(output_dir="data/raw"))

            with st.status("Crawling OpenReview...", expanded=True) as status:
                st.write("Fetching / Downloading / Parsing / Indexing ...")
                papers = ingestor.ingest_venue(
                    venue_id=venue_id,
                    limit=limit,
                    download_pdfs=download_pdfs,
                    parse_pdfs=parse_pdfs,
                    max_pdf_pages=max_pages if parse_pdfs else None,
                    max_downloads=limit if download_pdfs else None,
                )
                status.update(label="Crawl Complete!", state="complete")

            st.success(f"Successfully ingested {len(papers)} papers.")


def _render_research_agent(*, use_system_key: bool, user_api_key: str, user_base_url: str, model_name: str) -> None:
    st.header("ğŸ§  Deep Insight Agent")

    col_chat, col_context = st.columns([0.65, 0.35], gap="large")

    with col_chat:
        # åˆå§‹åŒ–/è¿æ¥çŸ¥è¯†åº“ï¼ˆä¸ä¾èµ– LLMï¼‰
        kb = KnowledgeBase()
        kb.initialize_db()

        # å±•ç¤ºå†å²å¯¹è¯ï¼ˆåªæ”¾ç”¨æˆ·é—®é¢˜/ç®€çŸ­çŠ¶æ€ï¼Œä¸æŠŠæ•´ç¯‡æŠ¥å‘Šå¡è¿›èŠå¤©æ°”æ³¡ï¼‰
        for msg in st.session_state["messages"]:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

        user_query = st.chat_input("Ask a research question")

        # æ–°é—®é¢˜ï¼šç”Ÿæˆ planï¼ˆå¾…ç”¨æˆ·æ‰¹å‡†ï¼‰
        if user_query:
            st.session_state["messages"].append({"role": "user", "content": user_query})
            with st.chat_message("user"):
                st.markdown(user_query)

            # æ¸…ç©ºä¸Šä¸€æ¬¡ç»“æœ
            st.session_state["research_notes"] = []
            st.session_state["final_report"] = ""
            st.session_state["verification_result"] = None
            st.session_state["plan_approved"] = False
            st.session_state["pending_plan"] = None
            st.session_state["plan_editor_text"] = ""

            # è§£æè®¤è¯ä¿¡æ¯ -> åˆå§‹åŒ– LLM
            active_api_key = os.getenv("OPENAI_API_KEY") if use_system_key else (user_api_key.strip() or None)
            active_base_url = os.getenv("OPENAI_BASE_URL", None) if use_system_key else (user_base_url.strip() or None)
            llm = get_llm_client(api_key=active_api_key, base_url=active_base_url)
            if not llm:
                st.error("Authentication Failed. Please provide a valid Access Code or your own API Key.")
            else:
                # DB statsï¼ˆç»™ planner ç”¨ï¼‰
                df = kb.search_structured()
                stats = {"count": int(len(df))}
                if hasattr(df, "empty") and not df.empty:
                    try:
                        stats["avg_rating"] = float(df["rating"].dropna().mean()) if "rating" in df.columns else None
                    except Exception:
                        stats["avg_rating"] = None
                    try:
                        if "decision" in df.columns:
                            stats["decision_counts"] = (
                                df["decision"].fillna("UNKNOWN").value_counts().head(10).to_dict()
                            )
                    except Exception:
                        pass

                planner = PlannerAgent(llm, model=model_name)
                with st.status("Planning...", expanded=True) as status:
                    st.write("Generating Research Plan...")
                    plan = planner.generate_plan(user_query, stats)
                    st.session_state["pending_plan"] = plan
                    st.session_state["plan_editor_text"] = json.dumps(plan, ensure_ascii=False, indent=2)
                    status.update(label="Plan Generated (Waiting for Approval)", state="complete")

        # è®¡åˆ’å®¡æ ¸/ç¼–è¾‘/æ‰¹å‡†
        if st.session_state.get("pending_plan") and not st.session_state.get("plan_approved"):
            st.subheader("Step 1 Â· Review & Approve Plan")
            plan_text = st.text_area(
                "Plan JSON (editable)",
                key="plan_editor_text",
                height=320,
            )

            col_a, col_b = st.columns(2)
            with col_a:
                if st.button("Apply Edits"):
                    try:
                        st.session_state["pending_plan"] = json.loads(plan_text)
                        st.success("Plan updated.")
                    except Exception as e:
                        st.error(f"Plan JSON parse error: {e}")

            with col_b:
                if st.button("Approve & Run"):
                    # å†æ¬¡è§£æè®¤è¯ä¿¡æ¯ -> åˆå§‹åŒ– LLM
                    active_api_key = os.getenv("OPENAI_API_KEY") if use_system_key else (user_api_key.strip() or None)
                    active_base_url = os.getenv("OPENAI_BASE_URL", None) if use_system_key else (user_base_url.strip() or None)
                    llm = get_llm_client(api_key=active_api_key, base_url=active_base_url)
                    if not llm:
                        st.error("Authentication Failed. Please provide a valid Access Code or your own API Key.")
                    else:
                        try:
                            plan = json.loads(plan_text)
                        except Exception as e:
                            st.error(f"Plan JSON parse error: {e}")
                            plan = None

                        if plan:
                            st.session_state["plan_approved"] = True

                            researcher = ResearcherAgent(kb, llm, model=model_name)
                            writer = WriterAgent(llm, model=model_name)
                            verifier = VerifierAgent(llm, model=model_name)

                            with st.status("Running...", expanded=True) as status:
                                st.write("Conducting Research...")
                                notes = researcher.execute_research(plan)
                                st.session_state["research_notes"] = notes

                                st.write("Writing Report...")
                                report = writer.write_report(plan, notes)
                                st.session_state["final_report"] = report

                                st.write("Verifying (Claim-level NLI)...")
                                chunk_map = {}
                                for n in notes:
                                    for e in (n.get("evidence") or []):
                                        cid = e.get("chunk_id")
                                        txt = e.get("text")
                                        if cid and txt and cid not in chunk_map:
                                            chunk_map[cid] = txt

                                verification = verifier.verify_report(report, {"chunks": chunk_map})
                                st.session_state["verification_result"] = verification

                                status.update(label="Completed", state="complete")

                            # ç»™èŠå¤©åŒºä¸€ä¸ªç®€çŸ­å›æ‰§ï¼ˆä¸è´´æ•´ç¯‡æŠ¥å‘Šï¼‰
                            v = st.session_state.get("verification_result") or {}
                            st.session_state["messages"].append(
                                {
                                    "role": "assistant",
                                    "content": f"æŠ¥å‘Šå·²ç”Ÿæˆã€‚æ ¸æŸ¥ï¼švalid={v.get('is_valid')}, score={v.get('score')}.ï¼ˆè¯¦è§å³ä¾§æº¯æº/æ ¸æŸ¥é¢æ¿ï¼‰",
                                }
                            )

        # è¾“å‡ºæœ€ç»ˆæŠ¥å‘Šï¼ˆå·¦æ ï¼‰
        if st.session_state.get("final_report"):
            st.divider()
            st.subheader("Final Report")
            st.markdown(st.session_state["final_report"])

            v = st.session_state.get("verification_result")
            if isinstance(v, dict) and v:
                st.caption(f"Verification: valid={v.get('is_valid')} Â· score={v.get('score')} Â· {v.get('notes')}")

    with col_context:
        st.subheader("ğŸ” Traceability")

        tab_evi, tab_ver = st.tabs(["Evidence", "Verification"])

        with tab_evi:
            notes = st.session_state.get("research_notes") or []
            if not notes:
                st.markdown("*No evidence yet. Ingest data and run a query.*")
            else:
                for note in notes:
                    section_name = note.get("section", "Section")
                    with st.expander(f"ğŸ“Œ {section_name}", expanded=False):
                        if note.get("filters"):
                            st.caption(f"Filters: {json.dumps(note.get('filters'), ensure_ascii=False)}")

                        # å±•ç¤º key pointsï¼ˆå¸¦ citationsï¼‰
                        if note.get("key_points"):
                            st.markdown("**Key Points**")
                            st.json(note.get("key_points"), expanded=False)

                        evidence = note.get("evidence") or []
                        if not evidence:
                            st.markdown("*No evidence snippets for this section.*")
                        else:
                            for e in evidence:
                                pid = e.get("paper_id")
                                title = e.get("title", "")
                                cid = e.get("chunk_id")
                                src = e.get("source")
                                st.markdown(f"**{title}**  \n`paper_id={pid}` Â· `chunk_id={cid}` Â· `source={src}`")
                                st.code((e.get("text") or "")[:1200])

        with tab_ver:
            v = st.session_state.get("verification_result")
            if not isinstance(v, dict) or not v:
                st.markdown("*No verification yet.*")
            else:
                st.caption(f"valid={v.get('is_valid')} Â· score={v.get('score')} Â· {v.get('notes')}")
                evals = v.get("evaluations") or []
                if evals:
                    try:
                        import pandas as pd

                        st.dataframe(pd.DataFrame(evals), use_container_width=True)
                    except Exception:
                        st.json(evals, expanded=False)
                else:
                    st.json(v, expanded=False)


def main() -> None:
    load_env()

    if not _ensure_streamlit_context():
        print("è¿™æ˜¯ä¸€ä¸ª Streamlit åº”ç”¨ï¼Œè¯·ä½¿ç”¨ï¼šstreamlit run ui/app.py")
        return

    st.set_page_config(
        page_title="MUJICA: NeurIPS 2024 Deep Insight",
        page_icon="ğŸŒŒ",
        layout="wide",
        initial_sidebar_state="expanded",
    )

    _local_css(Path(__file__).with_name("style.css"))

    st.session_state.setdefault("messages", [])
    st.session_state.setdefault("research_notes", [])
    st.session_state.setdefault("final_report", "")
    st.session_state.setdefault("pending_plan", None)
    st.session_state.setdefault("plan_editor_text", "")
    st.session_state.setdefault("plan_approved", False)
    st.session_state.setdefault("verification_result", None)

    with st.sidebar:
        st.title("ğŸŒŒ MUJICA")
        st.caption("Multi-stage User-Judged Integration")

        st.divider()
        mode = st.radio("System Mode", ["Research Agent", "Data Dashboard"])

        st.divider()
        st.subheader("Model Configuration")

        SYSTEM_ACCESS_CODE = os.getenv("MUJICA_ACCESS_CODE", "mujica2024")
        auth_code = st.text_input(
            "Access Code (Optional)",
            type="password",
            help="Enter code to use System API Key",
        )

        use_system_key = False
        if auth_code == SYSTEM_ACCESS_CODE:
            use_system_key = True
            st.success("Authentication: Authorized âœ…")
        elif auth_code:
            st.error("Authentication: Invalid Code âŒ")

        user_api_key = st.text_input(
            "API Key",
            type="password",
            disabled=use_system_key,
            help="Required if no Access Code provided",
        )
        user_base_url = st.text_input("Base URL (Optional)", placeholder="e.g. https://api.deepseek.com/v1")
        model_name = st.text_input(
            "Model Name",
            value=os.getenv("MUJICA_DEFAULT_MODEL", "gpt-4o"),
            help="e.g. gpt-3.5-turbo, deepseek-chat",
        )

        st.caption(f"System Status: {'Using System Key' if use_system_key else 'Using User Key'}")

    if mode == "Data Dashboard":
        _render_data_dashboard()
    else:
        _render_research_agent(
            use_system_key=use_system_key,
            user_api_key=user_api_key,
            user_base_url=user_base_url,
            model_name=model_name,
        )


if __name__ == "__main__":
    main()
